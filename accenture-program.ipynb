{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d521b156",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-11-13T11:54:35.011176Z",
     "iopub.status.busy": "2022-11-13T11:54:35.010587Z",
     "iopub.status.idle": "2022-11-13T11:54:35.025524Z",
     "shell.execute_reply": "2022-11-13T11:54:35.024421Z"
    },
    "papermill": {
     "duration": 0.023539,
     "end_time": "2022-11-13T11:54:35.028516",
     "exception": false,
     "start_time": "2022-11-13T11:54:35.004977",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/datathon-2022-upc-accenture/product_weight_class.csv\n",
      "/kaggle/input/datathon-2022-upc-accenture/UPC Datathon_challenge_NovFY23.pdf\n",
      "/kaggle/input/datathon-2022-upc-accenture/cities_data_costs.csv\n",
      "/kaggle/input/datathon-2022-upc-accenture/cities_data.csv\n",
      "/kaggle/input/datathon-2022-upc-accenture/orders.csv\n",
      "/kaggle/input/datathon-2022-upc-accenture/starter-notebook.ipynb\n",
      "/kaggle/input/datathon-2022-upc-accenture/test.csv\n",
      "/kaggle/input/datathon-2022-upc-accenture/product_attributes.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00e5437e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T11:54:35.035196Z",
     "iopub.status.busy": "2022-11-13T11:54:35.034810Z",
     "iopub.status.idle": "2022-11-13T11:54:36.100686Z",
     "shell.execute_reply": "2022-11-13T11:54:36.099389Z"
    },
    "papermill": {
     "duration": 1.072426,
     "end_time": "2022-11-13T11:54:36.103563",
     "exception": false,
     "start_time": "2022-11-13T11:54:35.031137",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Rotterdam': 0.16921047383841328, 'Athens': 0.3741508954193759, 'Barcelona': 0.2702263870848024}\n",
      "{'v_002': 0.1994466388772594, 'v_004': 0.2569492898782327, 'v_001': 0.38209853328318916, 'v_003': 0.2502524159815376}\n",
      "{'DTP': 0.3115195443955475, 'CRF': 0.19820502360277406, 'DTD': 0.25149480268604546}\n",
      "{'Venlo': 0.18738396624472572, 'Rome': 0.2575441412520064, 'Lille': 0.3595823575331772, 'Bratislava': 0.3308839902026275, 'Warsaw': 0.22755173068404733, 'Dusseldorf': 0.18381530595941845, 'Hamburg': 0.20204841713221602, 'Liege': 0.22171945701357465, 'Zaragoza': 0.3497337053005326}\n",
      "{'Marseille': 0.32769390942217597, 'Paris': 0.30714501967907964, 'Milan': 0.20382626680455015, 'Berlin': 0.19584479071188513, 'Munich': 0.1941458574499752, 'Prague': 0.20864197530864198, 'Rome': 0.22538860103626943, 'Madrid': 0.24071064890044416, 'Naples': 0.21529850746268656, 'Athens': 0.2653515749284123, 'Lisbon': 0.32701421800947866, 'Turin': 0.19692020531964535, 'Vienna': 0.20310734463276836, 'Stockholm': 0.28258221680876977, 'Barcelona': 0.22594619243046055, 'Amsterdam': 0.19564012562349897, 'Valencia': 0.23809523809523808, 'Cologne': 0.1831454918032787, 'Malmö': 0.2598243180767453, 'Budapest': 0.2088235294117647, 'Hanover': 0.18755555555555556, 'Helsinki': 0.3217884130982368, 'Copenhagen': 0.2667623539060898, 'Bucharest': 0.2276252983293556, 'Bremen': 0.1761786600496278, 'Lyon': 0.3249023236685174, 'Porto': 0.31744604316546765, 'Bordeaux': 0.3195558297347316}\n",
      "[0.32769390942217597, 0.30714501967907964, 0.20382626680455015, 0.19584479071188513, 0.1941458574499752, 0.20864197530864198, 0.22538860103626943, 0.24071064890044416, 0.21529850746268656, 0.2653515749284123, 0.32701421800947866, 0.19692020531964535, 0.20310734463276836, 0.28258221680876977, 0.22594619243046055, 0.19564012562349897, 0.23809523809523808, 0.1831454918032787, 0.2598243180767453, 0.2088235294117647, 0.18755555555555556, 0.3217884130982368, 0.2667623539060898, 0.2276252983293556, 0.1761786600496278, 0.3249023236685174, 0.31744604316546765, 0.3195558297347316]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nunitsDictionary = {}\\nunitsList = []\\nunitsInfo = []\\nfor dada in train_data.units:\\n    if not dada in unitsList:\\n        unitsList.append(dada)\\n\\nfor unit in unitsList:\\n    customOrders = train_data.loc[train_data.units == unit][\"late_order\"]\\n    quantityOfCustomOrders = len(customOrders)\\n    customOrders = pd.DataFrame(customOrders)\\n    customOrders = customOrders.loc[customOrders.late_order, :]\\n    unitsInfo.append([str(unit), len(customOrders)/quantityOfCustomOrders])\\n\\nfor i in range(len(unitsList)):\\n    if ()\\n    unitsDictionary.update({unitsInfo[i][0]: unitsInfo[i][1]})\\nprint(unitsDictionary)\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import training data\n",
    "train_data = pd.read_csv(\"/kaggle/input/datathon-2022-upc-accenture/orders.csv\",sep=\";\")\n",
    "train_data.head()\n",
    "\n",
    "#create a data frame with the training data\n",
    "df = pd.DataFrame(train_data)\n",
    "\n",
    "\n",
    "\n",
    "#get all \"types\" of port: Barcelona, Athens...\n",
    "origin_portList = []\n",
    "#check, for every row, if the origin city is already in the city list. If not, put it there\n",
    "for dada in train_data.origin_port:\n",
    "    if not dada in origin_portList:\n",
    "        origin_portList.append(dada)\n",
    "\n",
    "#save: data name, how many of that data, and percent value of delayed shipments\n",
    "origin_portInfo = []\n",
    "origin_portDictionary = {}\n",
    "\n",
    "#for each different city, get the delayed shipment column, and extract the falses to get only the per cent of True\n",
    "for city in origin_portList:\n",
    "    cityOrders = train_data.loc[train_data.origin_port == city][\"late_order\"]\n",
    "    quantityOfCityOrders = len(cityOrders)\n",
    "    cityOrders = pd.DataFrame(cityOrders)\n",
    "    cityOrders = cityOrders.loc[cityOrders.late_order, :]\n",
    "    origin_portInfo.append([str(city), quantityOfCityOrders, len(cityOrders)/quantityOfCityOrders])\n",
    "#Fix BCN, ATHENAS\n",
    "origin_portInfo[2][1], origin_portInfo[2][2] = origin_portInfo[2][1]+origin_portInfo[3][1], (((origin_portInfo[2][1]*origin_portInfo[2][2])+(origin_portInfo[3][1]*origin_portInfo[3][2]))/(origin_portInfo[2][1]+origin_portInfo[3][1]))\n",
    "origin_portInfo[1][1], origin_portInfo[1][2] = origin_portInfo[1][1]+origin_portInfo[4][1], (((origin_portInfo[1][1]*origin_portInfo[1][2])+(origin_portInfo[4][1]*origin_portInfo[4][2]))/(origin_portInfo[1][1]+origin_portInfo[4][1]))\n",
    "del origin_portInfo[3:5]\n",
    "\n",
    "#fill dictionary\n",
    "for i in range(len(origin_portInfo)):\n",
    "    origin_portDictionary.update({origin_portInfo[i][0]: origin_portInfo[i][2]})\n",
    "print(origin_portDictionary)\n",
    "    \n",
    "    \n",
    "    \n",
    "third_partyDictionary = {}\n",
    "third_partyList = []\n",
    "third_partyInfo = []\n",
    "for dada in train_data[\"3pl\"]:\n",
    "    if not dada in third_partyList:\n",
    "        third_partyList.append(dada)\n",
    "\n",
    "for tp in third_partyList:\n",
    "    tpOrders = train_data.loc[train_data[\"3pl\"] == tp][\"late_order\"]\n",
    "    quantityOfTpOrders = len(tpOrders)\n",
    "    tpOrders = pd.DataFrame(tpOrders)\n",
    "    tpOrders = tpOrders.loc[tpOrders.late_order, :]\n",
    "    third_partyInfo.append([str(tp), len(tpOrders)/quantityOfTpOrders])\n",
    " \n",
    "for i in range(len(third_partyList)):\n",
    "    third_partyDictionary.update({third_partyInfo[i][0]: third_partyInfo[i][1]})\n",
    "print(third_partyDictionary)\n",
    "    \n",
    "    \n",
    "customs_proceduresDictionary = {}\n",
    "customs_proceduresList = []\n",
    "customs_proceduresInfo = []\n",
    "for dada in train_data.customs_procedures:\n",
    "    if not dada in customs_proceduresList:\n",
    "        customs_proceduresList.append(dada)\n",
    "\n",
    "for customs in customs_proceduresList:\n",
    "    customOrders = train_data.loc[train_data.customs_procedures == customs][\"late_order\"]\n",
    "    quantityOfCustomOrders = len(customOrders)\n",
    "    customOrders = pd.DataFrame(customOrders)\n",
    "    customOrders = customOrders.loc[customOrders.late_order, :]\n",
    "    customs_proceduresInfo.append([str(customs), len(customOrders)/quantityOfCustomOrders])\n",
    "\n",
    "for i in range(len(customs_proceduresList)):\n",
    "    customs_proceduresDictionary.update({customs_proceduresInfo[i][0]: customs_proceduresInfo[i][1]})\n",
    "print(customs_proceduresDictionary)\n",
    "        \n",
    "    \n",
    "    \n",
    "        \n",
    "logistic_hubDictionary = {}\n",
    "logistic_hubList = []\n",
    "logistic_hubInfo = []\n",
    "for dada in train_data.logistic_hub:\n",
    "    if not dada in logistic_hubList:\n",
    "        logistic_hubList.append(dada)\n",
    "#remove nan:\n",
    "del logistic_hubList[5]\n",
    "\n",
    "for hub in logistic_hubList:\n",
    "    logisticOrders = train_data.loc[train_data.logistic_hub == hub][\"late_order\"]\n",
    "    quantityOflogisticOrders = len(logisticOrders)\n",
    "    logisticOrders = pd.DataFrame(logisticOrders)\n",
    "    logisticOrders = logisticOrders.loc[logisticOrders.late_order, :]\n",
    "    logistic_hubInfo.append([str(hub), len(logisticOrders)/quantityOflogisticOrders])\n",
    "    \n",
    "for i in range(len(logistic_hubList)):\n",
    "    logistic_hubDictionary.update({logistic_hubInfo[i][0]: logistic_hubInfo[i][1]})\n",
    "print(logistic_hubDictionary)        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "customerDictionary = {}\n",
    "customerList = []\n",
    "customerInfo = []\n",
    "for dada in train_data.customer:\n",
    "    if not dada in customerList:\n",
    "        customerList.append(dada)\n",
    "        \n",
    "for costumer in customerList:\n",
    "    customOrders = train_data.loc[train_data.customer == costumer][\"late_order\"]\n",
    "    quantityOfCustomOrders = len(customOrders)\n",
    "    customOrders = pd.DataFrame(customOrders)\n",
    "    customOrders = customOrders.loc[customOrders.late_order, :]\n",
    "    customerInfo.append([str(costumer), len(customOrders)/quantityOfCustomOrders])\n",
    "\n",
    "for i in range(len(customerList)):\n",
    "    customerDictionary.update({customerInfo[i][0]: customerInfo[i][1]})\n",
    "print(customerDictionary)\n",
    "\n",
    "llistaaa = []\n",
    "for customer in customerList:\n",
    "    llistaaa.append(customerDictionary[customer])\n",
    "print(llistaaa)\n",
    "\n",
    "#number data is not relevant enough\n",
    "\"\"\"\n",
    "unitsDictionary = {}\n",
    "unitsList = []\n",
    "unitsInfo = []\n",
    "for dada in train_data.units:\n",
    "    if not dada in unitsList:\n",
    "        unitsList.append(dada)\n",
    "\n",
    "for unit in unitsList:\n",
    "    customOrders = train_data.loc[train_data.units == unit][\"late_order\"]\n",
    "    quantityOfCustomOrders = len(customOrders)\n",
    "    customOrders = pd.DataFrame(customOrders)\n",
    "    customOrders = customOrders.loc[customOrders.late_order, :]\n",
    "    unitsInfo.append([str(unit), len(customOrders)/quantityOfCustomOrders])\n",
    "\n",
    "for i in range(len(unitsList)):\n",
    "    if ()\n",
    "    unitsDictionary.update({unitsInfo[i][0]: unitsInfo[i][1]})\n",
    "print(unitsDictionary)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3a7c62e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T11:54:36.111133Z",
     "iopub.status.busy": "2022-11-13T11:54:36.110230Z",
     "iopub.status.idle": "2022-11-13T11:54:38.387861Z",
     "shell.execute_reply": "2022-11-13T11:54:38.386669Z"
    },
    "papermill": {
     "duration": 2.284069,
     "end_time": "2022-11-13T11:54:38.390545",
     "exception": false,
     "start_time": "2022-11-13T11:54:36.106476",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           order_id           late_order\n",
      "0      0e364fa5c795   0.1877644452521206\n",
      "1      3ef49bd5a55b   0.2002738616659161\n",
      "2      9ab5b9685bd5  0.25039834050681187\n",
      "3      bfce5b4fc4fa  0.20203702722181732\n",
      "4      d94453ec8ec5   0.2742082011453454\n",
      "...             ...                  ...\n",
      "28558  d268acf6459e  0.23401122529609503\n",
      "28559  1aefc30b0eb3   0.2271133879038599\n",
      "28560  646a2e50e170   0.2127177962841793\n",
      "28561  bf5177549be9   0.2881455588580621\n",
      "28562  525dafc0ad62  0.20647391242823576\n",
      "\n",
      "[28563 rows x 2 columns]\n",
      "{'Rotterdam': 0.16921047383841328, 'Athens': 0.3741508954193759, 'Barcelona': 0.2702263870848024}\n",
      "{'v_002': 0.1994466388772594, 'v_004': 0.2569492898782327, 'v_001': 0.38209853328318916, 'v_003': 0.2502524159815376}\n",
      "{'Venlo': 0.18738396624472572, 'Rome': 0.2575441412520064, 'Lille': 0.3595823575331772, 'Bratislava': 0.3308839902026275, 'Warsaw': 0.22755173068404733, 'Dusseldorf': 0.18381530595941845, 'Hamburg': 0.20204841713221602, 'Liege': 0.22171945701357465, 'Zaragoza': 0.3497337053005326}\n",
      "{'DTP': 0.3115195443955475, 'CRF': 0.19820502360277406, 'DTD': 0.25149480268604546}\n",
      "{'Marseille': 0.32769390942217597, 'Paris': 0.30714501967907964, 'Milan': 0.20382626680455015, 'Berlin': 0.19584479071188513, 'Munich': 0.1941458574499752, 'Prague': 0.20864197530864198, 'Rome': 0.22538860103626943, 'Madrid': 0.24071064890044416, 'Naples': 0.21529850746268656, 'Athens': 0.2653515749284123, 'Lisbon': 0.32701421800947866, 'Turin': 0.19692020531964535, 'Vienna': 0.20310734463276836, 'Stockholm': 0.28258221680876977, 'Barcelona': 0.22594619243046055, 'Amsterdam': 0.19564012562349897, 'Valencia': 0.23809523809523808, 'Cologne': 0.1831454918032787, 'Malmö': 0.2598243180767453, 'Budapest': 0.2088235294117647, 'Hanover': 0.18755555555555556, 'Helsinki': 0.3217884130982368, 'Copenhagen': 0.2667623539060898, 'Bucharest': 0.2276252983293556, 'Bremen': 0.1761786600496278, 'Lyon': 0.3249023236685174, 'Porto': 0.31744604316546765, 'Bordeaux': 0.3195558297347316}\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "#import test data\n",
    "test_data = pd.read_csv(\"/kaggle/input/datathon-2022-upc-accenture/test.csv\",sep=\";\")\n",
    "test_data.head()\n",
    "\n",
    "#create a data frame with the test data\n",
    "testFrame = pd.DataFrame(test_data)\n",
    "\n",
    "probabilities = []\n",
    "\n",
    "for index, row in testFrame.iterrows():\n",
    "    if row[1] == \"ATHENAS\":\n",
    "        originPort = origin_portDictionary[\"Athens\"]\n",
    "    elif row[1] == \"BCN\":\n",
    "        originPort = origin_portDictionary[\"Barcelona\"]\n",
    "    else:\n",
    "        originPort = origin_portDictionary[row[1]] \n",
    "    thirdParty = third_partyDictionary[row[2]] * .85\n",
    "    customs = customs_proceduresDictionary[row[3]] * .9\n",
    "    customer = customerDictionary[row[5]] \n",
    "    \n",
    "    if(pd.notna(row[4])):\n",
    "        logisticHub = logistic_hubDictionary[row[4]]\n",
    "        probabilities.append(str(((originPort+thirdParty+logisticHub+customs+customer)/5)))\n",
    "    else:   \n",
    "        probabilities.append(str((originPort+thirdParty+customs+customer)/4))\n",
    "\n",
    "submission = pd.DataFrame({\"order_id\": test_data.order_id, \"late_order\": probabilities})\n",
    "submission.to_csv(\"submission_kaggle.csv\", index=False)\n",
    "\n",
    "print(submission)\n",
    "print(origin_portDictionary)\n",
    "print(third_partyDictionary)\n",
    "print(logistic_hubDictionary)\n",
    "print(customs_proceduresDictionary)\n",
    "print(customerDictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2be6cd4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T11:54:38.397748Z",
     "iopub.status.busy": "2022-11-13T11:54:38.397388Z",
     "iopub.status.idle": "2022-11-13T11:54:38.526327Z",
     "shell.execute_reply": "2022-11-13T11:54:38.524829Z"
    },
    "papermill": {
     "duration": 0.135662,
     "end_time": "2022-11-13T11:54:38.529085",
     "exception": false,
     "start_time": "2022-11-13T11:54:38.393423",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rotterdam DTP: 11035, CRF: 29350, DTD: 24806\n",
      "Athens DTP: 4285, CRF: 11553, DTD: 9814\n",
      "Barcelona DTP: 3115, CRF: 8406, DTD: 7040\n",
      "BCN DTP: 534, CRF: 1325, DTD: 1136\n",
      "ATHENAS DTP: 346, CRF: 843, DTD: 688\n"
     ]
    }
   ],
   "source": [
    "#get all \"types\" of port: Barcelona, Athens...\n",
    "origin_portList = []\n",
    "#check, for every row, if the origin city is already in the city list. If not, put it there\n",
    "for dada in train_data.origin_port:\n",
    "    if not dada in origin_portList:\n",
    "        origin_portList.append(dada)\n",
    "\n",
    "#save: data name, how many of that data, and percent value of delayed shipments\n",
    "origin_portInfo = []\n",
    "origin_portDictionary = {}\n",
    "\n",
    "#for each different city, get the delayed shipment column, and extract the falses to get only the per cent of True\n",
    "for city in origin_portList:\n",
    "    cityOrders = train_data.loc[train_data.origin_port == city][\"customs_procedures\"]\n",
    "    dtp = 0\n",
    "    crf = 0\n",
    "    dtd = 0\n",
    "    for i in cityOrders:\n",
    "        if i == \"DTP\":\n",
    "            dtp += 1\n",
    "        elif i == \"CRF\":\n",
    "            crf += 1\n",
    "        else:\n",
    "            dtd += 1\n",
    "    print(city + \" DTP: \" + str(dtp) + \", CRF: \" + str(crf) + \", DTD: \" + str(dtd))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 12.286425,
   "end_time": "2022-11-13T11:54:39.152740",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-11-13T11:54:26.866315",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
